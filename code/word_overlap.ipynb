{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word overlap.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_Jf_xC6DtGQ",
        "outputId": "ef63acda-e2ba-425b-8006-85689b4b22bb"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "drive.mount('/content/drive')\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vbcf4mPCXQph",
        "outputId": "c886b8e4-2657-4d70-e048-756c6dcc7bd7"
      },
      "source": [
        "!pip install google_trans_new"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google_trans_new\n",
            "  Downloading https://files.pythonhosted.org/packages/f9/7b/9f136106dc5824dc98185c97991d3cd9b53e70a197154dd49f7b899128f6/google_trans_new-1.1.9-py3-none-any.whl\n",
            "Installing collected packages: google-trans-new\n",
            "Successfully installed google-trans-new-1.1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfO61jIH5Gm0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15e3c01e-277c-4edb-86be-5ec9c70d929c"
      },
      "source": [
        "import io\r\n",
        "import numpy as np\r\n",
        "from google_trans_new import google_translator\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords') \r\n",
        "import string"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTNhw1QZ1DgX"
      },
      "source": [
        "### Importing data from json file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFPN0nyj7pA8"
      },
      "source": [
        "import json \r\n",
        "  \r\n",
        "# Opening JSON file \r\n",
        "f = open('/content/drive/My Drive/actors.json',) \r\n",
        "  \r\n",
        "# returns JSON object as  \r\n",
        "# a dictionary \r\n",
        "data = json.load(f) \r\n",
        "  \r\n",
        "# Iterating through the json \r\n",
        "# list \r\n",
        "d = {}\r\n",
        "d = data\r\n",
        "  \r\n",
        "# Closing file \r\n",
        "f.close() "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b8kW8qj1KCt"
      },
      "source": [
        "### Storing sentences and triples from one article\r\n",
        "Here we store all the sentences and the triples from one article. The article is about the actress 'Kalpana'. We display 5 sentences and 5 triples corresponding to her here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0xYWKfDFBJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd15d06-59b5-45ab-99f4-876b3ea9b3a2"
      },
      "source": [
        "sentences = d['Q6354355']['sentences']\r\n",
        "triples = d['Q6354355']['triples']\r\n",
        "print(\"5 sentences : \\n\")\r\n",
        "for s in sentences[:5]:\r\n",
        "  print(s,\"\\n\")\r\n",
        "print(\"5 triples : \\n\")\r\n",
        "for t in triples[:5]:\r\n",
        "  print(t,\"\\n\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 sentences : \n",
            "\n",
            "कल्पना प्रियदर्शनी एक भारतीय फ़िल्म अभिनेत्री थी, जो दक्षिण भारतीय फिल्मों में मुख्य रूप से मलयालम और तमिल फिल्मों में अपने काम के लिए प्रसिद्ध थी \n",
            "\n",
            "उन्होंने दक्षिण भारतीय भाषाओं में ३०० से भी अधिक फिल्मों में अभिनय किया है \n",
            "\n",
            "उन्होंने एक बाल कलाकार के रूप में अपना करियर शुरू किया १९७० के दशक से \n",
            "\n",
            "६०वें राष्ट्रीय फिल्म अवॉर्ड्स में, उन्होंने थानीचला नंजन (2012) में उनके प्रदर्शन के लिए सर्वश्रेष्ठ सहायक अभिनेत्री का पुरस्कार जीता \n",
            "\n",
            "कल्पना का जन्म मंच कलाकार चवरा वी. पी. नायर और विजयलक्ष्मी के हुआ था \n",
            "\n",
            "5 triples : \n",
            "\n",
            "['Kalpana', 'place of birth', 'Kerala'] \n",
            "\n",
            "['Kalpana', 'place of death', 'Hyderabad'] \n",
            "\n",
            "['Kalpana', 'sex or gender', 'female'] \n",
            "\n",
            "['Kalpana', 'spouse', 'Anil Kumar'] \n",
            "\n",
            "['Kalpana', 'country of citizenship', 'India'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rh8jjCs5cCz"
      },
      "source": [
        "\r\n",
        "def load_vec(emb_path, nmax=50000):\r\n",
        "    vectors = []\r\n",
        "    word2id = {}\r\n",
        "    with io.open(emb_path, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\r\n",
        "        next(f)\r\n",
        "        for i, line in enumerate(f):\r\n",
        "            word, vect = line.rstrip().split(' ', 1)\r\n",
        "            vect = np.fromstring(vect, sep=' ')\r\n",
        "            assert word not in word2id, 'word found twice'\r\n",
        "            vectors.append(vect)\r\n",
        "            word2id[word] = len(word2id)\r\n",
        "            if len(word2id) == nmax:\r\n",
        "                break\r\n",
        "    id2word = {v: k for k, v in word2id.items()}\r\n",
        "    embeddings = np.vstack(vectors)\r\n",
        "    return embeddings, id2word, word2id"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtoLKVcW3u_7"
      },
      "source": [
        "### Getting source and target embeddings from the aligned multilingual vector space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69tEieKr5fs3"
      },
      "source": [
        "dir = '/content/drive/My Drive/Algo Name detection implementation/Text/'\r\n",
        "src_path = '/content/drive/My Drive/wiki.hi.align.vec'\r\n",
        "tgt_path = '/content/drive/My Drive/wiki.en.align.vec'\r\n",
        "nmax = 50000  # maximum number of word embeddings to load\r\n",
        "\r\n",
        "src_embeddings, src_id2word, src_word2id = load_vec(src_path, nmax)\r\n",
        "tgt_embeddings, tgt_id2word, tgt_word2id = load_vec(tgt_path, nmax)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTUW3Tba6JrL"
      },
      "source": [
        "**Get Nearest Neighbours**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2167UAg6TLk"
      },
      "source": [
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "stop_words = set(stopwords.words('english'))\r\n",
        "def get_nn(word, src_emb, src_id2word, tgt_emb, tgt_id2word, K=5):\r\n",
        "    # print(\"Nearest neighbors of \\\"%s\\\":\" % word)\r\n",
        "    word2id = {v: k for k, v in src_id2word.items()}\r\n",
        "    targetwordlist = []                               # List of target words for the source word \r\n",
        "    if word in word2id:                               #Check if word is in vocab\r\n",
        "      word_emb = src_emb[word2id[word]]\r\n",
        "      scores = (tgt_emb / np.linalg.norm(tgt_emb, 2, 1)[:, None]).dot(word_emb / np.linalg.norm(word_emb))\r\n",
        "      k_best = scores.argsort()[-K:][::-1]\r\n",
        "      for i, idx in enumerate(k_best):\r\n",
        "          # print((scores[idx], tgt_id2word[idx]))      #To give both distance and word\r\n",
        "          if tgt_id2word[idx] not in stop_words:\r\n",
        "            targetwordlist.append(tgt_id2word[idx].lower())\r\n",
        "      return targetwordlist\r\n",
        "    else:\r\n",
        "      translator = google_translator()\r\n",
        "      translate_text = translator.translate(word,lang_tgt='en') \r\n",
        "      transw = translate_text\r\n",
        "      if transw not in stop_words:\r\n",
        "      # print(word,\" - Translated - \",transw)\r\n",
        "        return [transw.lower()]\r\n",
        "      "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ofOpGxa6YXT",
        "outputId": "0d6b78e9-a8b2-499f-8ee3-e37cada3ec22"
      },
      "source": [
        "# nearest neighbors in the source space\r\n",
        "src_word = 'cat'\r\n",
        "get_nn(src_word, src_embeddings, src_id2word, src_embeddings, src_id2word, K=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cat', 'cats', 'catch', 'nocat', 'categorise']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2NAioDT5Mn2"
      },
      "source": [
        "These are the 5 nearest neighbours in English for the sample word - अभिनेता. We obtain these nearest neighbours from the aligned multilingual vector space. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIcCqGnE6clC",
        "outputId": "0cb831c4-7e07-49f5-e401-59d689ae8b6c"
      },
      "source": [
        "# printing nearest neighbors in the target space\r\n",
        "src_word = 'अभिनेता'\r\n",
        "l = get_nn(src_word, src_embeddings, src_id2word, tgt_embeddings, tgt_id2word, K=5)\r\n",
        "print(\"Top 5 nearest neighbours for the word : \",src_word)\r\n",
        "for i,e in enumerate(l):\r\n",
        "  print(\"\\n\",i+1,\". \",e)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 5 nearest neighbours for the word :  अभिनेता\n",
            "\n",
            " 1 .  actor\n",
            "\n",
            " 2 .  actors\n",
            "\n",
            " 3 .  actress\n",
            "\n",
            " 4 .  actresses\n",
            "\n",
            " 5 .  film\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vuyn1H8q39HU"
      },
      "source": [
        "**Function for word overlap**\r\n",
        "We simply return the number of words in common between two phrases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-LDbFsrafdq",
        "outputId": "8b7e4a91-a4fe-4678-e283-0f7470371a42"
      },
      "source": [
        "def wordoverlap(entity_text,sentence_text_list):\r\n",
        "  words = entity_text.split(' ')    #splitting the predicate's or object's words\r\n",
        "  score = 0                         # calculate no of word matches\r\n",
        "  for w in words:\r\n",
        "    if w.lower() in sentence_text_list:\r\n",
        "      score = score+1\r\n",
        "  return score\r\n",
        "print(\"Word overlap score for the phrases : 'cause of death' and 'actress died due to a bad cause of death' = \",wordoverlap(\"cause of death\",\"actress died due to a bad cause of death\"))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word overlap score for the phrases : 'cause of death' and 'actress died due to a bad cause of death' =  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty5d4ZFd7UaW"
      },
      "source": [
        "### Matching triples with sentences\r\n",
        "We find 5 English nearest neighbours for each word in the Hindi sentence. Then , we put all these english words in a list and find the total word overlap with the triples. We keep a threshold for a minimum word overlap score required to match a triple with the sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejgpy7TROe9D"
      },
      "source": [
        "\r\n",
        "# srcwordlist = ['विश्वविद्यालय', 'प्यार']\r\n",
        "# sentence = 'पढ़ाई अंगद बेदी ने अपनी शुरुआती पढ़ाई ज्ञान भारती स्कूल, दिल्ली से की, और स्नातक की पढाई सैंट स्टीफेंस कॉलेज, दिल्ली से पूरी की है'\r\n",
        "tgworddict = {}\r\n",
        "for sent in sentences:\r\n",
        "  srcwordlist = sent.split(' ')\r\n",
        "  tgwordlists = []\r\n",
        "  for src_word in srcwordlist:\r\n",
        "    # print(src_word)\r\n",
        "    src_word = src_word.translate(str.maketrans('', '', string.punctuation))  # Removing punct\r\n",
        "    tgtwords = get_nn(src_word, src_embeddings, src_id2word, tgt_embeddings, tgt_id2word, K=5)\r\n",
        "    if len(tgtwords)>1 and tgtwords!=None:\r\n",
        "      tgwordlists.extend(tgtwords)\r\n",
        "  tgworddict[sent] = tgwordlists"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6yeexNZSdTw",
        "outputId": "72874d1b-7240-48f0-a3fc-a6142731e2e1"
      },
      "source": [
        "matches_with_sent = {}\r\n",
        "for sent in tgworddict:\r\n",
        "  words = tgworddict[sent]\r\n",
        "  matches = []\r\n",
        "  for entity in triples:\r\n",
        "    predicate = entity[1]\r\n",
        "    obj = entity[2]\r\n",
        "    score_predicate = wordoverlap(predicate,words)\r\n",
        "    score_obj = wordoverlap(obj,words)\r\n",
        "    if score_predicate >0 or score_obj >0:\r\n",
        "      # print(predicate,\"-\",obj,\"-\",words)\r\n",
        "      matches.append([entity,score_predicate + score_obj])\r\n",
        "  if len(matches) >0:\r\n",
        "      # Sorting \r\n",
        "    matches = np.asarray(matches)\r\n",
        "    matches = matches[matches[:,1].argsort()][::-1]\r\n",
        "    matches_with_sent[sent] = matches[:,0]\r\n",
        " "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAIDZHZb8Bts"
      },
      "source": [
        "#### DIsplaying the matching sentences with the triples for the article about the actress - 'Kalpana'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N27fETqGS6pq",
        "outputId": "057289fd-ac6d-41d0-bc5e-3b6a3a02de11"
      },
      "source": [
        "for k,v in matches_with_sent.items():\r\n",
        "  print(\"\\n\")\r\n",
        "  print(\"*******************************************************************************\")\r\n",
        "  print(k)\r\n",
        "  print(\"===============================\")\r\n",
        "  print(\"\\t\\t\\t\\t\\t\\n\",v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "*******************************************************************************\n",
            "कल्पना प्रियदर्शनी एक भारतीय फ़िल्म अभिनेत्री थी, जो दक्षिण भारतीय फिल्मों में मुख्य रूप से मलयालम और तमिल फिल्मों में अपने काम के लिए प्रसिद्ध थी\n",
            "===============================\n",
            "\t\t\t\t\t\n",
            " [list(['Kalpana', 'work period (start)', '1977-01-01T00:00:00Z'])\n",
            " list(['Kalpana', 'languages spoken, written or signed', 'Malayalam'])\n",
            " list(['Kalpana', 'occupation', 'actor'])\n",
            " list(['Kalpana', 'country of citizenship', 'India'])]\n",
            "\n",
            "\n",
            "*******************************************************************************\n",
            "उन्होंने दक्षिण भारतीय भाषाओं में ३०० से भी अधिक फिल्मों में अभिनय किया है\n",
            "===============================\n",
            "\t\t\t\t\t\n",
            " [list(['Kalpana', 'languages spoken, written or signed', 'Malayalam'])\n",
            " list(['Kalpana', 'country of citizenship', 'India'])]\n",
            "\n",
            "\n",
            "*******************************************************************************\n",
            "उन्होंने एक बाल कलाकार के रूप में अपना करियर शुरू किया १९७० के दशक से\n",
            "===============================\n",
            "\t\t\t\t\t\n",
            " [list(['Kalpana', 'occupation', 'actor'])]\n",
            "\n",
            "\n",
            "*******************************************************************************\n",
            "६०वें राष्ट्रीय फिल्म अवॉर्ड्स में, उन्होंने थानीचला नंजन (2012) में उनके प्रदर्शन के लिए सर्वश्रेष्ठ सहायक अभिनेत्री का पुरस्कार जीता\n",
            "===============================\n",
            "\t\t\t\t\t\n",
            " [list(['Kalpana', 'occupation', 'actor'])]\n",
            "\n",
            "\n",
            "*******************************************************************************\n",
            "कल्पना का जन्म मंच कलाकार चवरा वी. पी. नायर और विजयलक्ष्मी के हुआ था\n",
            "===============================\n",
            "\t\t\t\t\t\n",
            " [list(['Kalpana', 'date of birth', '1965-10-05T00:00:00Z'])\n",
            " list(['Kalpana', 'date of birth', '1965-06-05T00:00:00Z'])\n",
            " list(['Kalpana', 'occupation', 'actor'])\n",
            " list(['Kalpana', 'place of birth', 'Kerala'])]\n",
            "\n",
            "\n",
            "*******************************************************************************\n",
            "अभिनेत्री कलरणजीनी और उर्वशी उनकी बहने हैं\n",
            "===============================\n",
            "\t\t\t\t\t\n",
            " [list(['Kalpana', 'occupation', 'actor'])]\n",
            "\n",
            "\n",
            "*******************************************************************************\n",
            "उन्होंने १९९८ में मलयालम फिल्म निर्देशक अनिल कुमार से शादी की और २०१२ में तलाक हो गया\n",
            "===============================\n",
            "\t\t\t\t\t\n",
            " [list(['Kalpana', 'spouse', 'Anil Kumar'])\n",
            " list(['Kalpana', 'languages spoken, written or signed', 'Malayalam'])\n",
            " list(['Kalpana', 'occupation', 'actor'])]\n",
            "\n",
            "\n",
            "*******************************************************************************\n",
            "कल्पना ने एक बाल कलाकार के रूप में अपना करियर शुरू किया विदर्भ मोटकुल फिल्म से\n",
            "===============================\n",
            "\t\t\t\t\t\n",
            " [list(['Kalpana', 'occupation', 'actor'])]\n",
            "\n",
            "\n",
            "*******************************************************************************\n",
            "कल्पना ने ओपिरी फिल्म की शूटिंग के लिए हैदराबाद गई थी\n",
            "===============================\n",
            "\t\t\t\t\t\n",
            " [list(['Kalpana', 'place of death', 'Hyderabad'])]\n",
            "\n",
            "\n",
            "*******************************************************************************\n",
            "उन्हें तुरत हस्पताल लेजाया गया पर उनकी रस्ते में ही मृत्यु हो गई\n",
            "===============================\n",
            "\t\t\t\t\t\n",
            " [list(['Kalpana', 'manner of death', 'natural causes'])\n",
            " list(['Kalpana', 'date of death', '2016-01-25T00:00:00Z'])\n",
            " list(['Kalpana', 'cause of death', 'myocardial infarction'])\n",
            " list(['Kalpana', 'place of death', 'Hyderabad'])]\n",
            "\n",
            "\n",
            "*******************************************************************************\n",
            "२०१३ सर्वश्रेष्ठ सहायक अभिनेत्री के लिए राष्ट्रीय फिल्म पुरस्कार फिल्म थानीचला नंजन के लिए\n",
            "===============================\n",
            "\t\t\t\t\t\n",
            " [list(['Kalpana', 'occupation', 'actor'])]\n",
            "\n",
            "\n",
            "*******************************************************************************\n",
            "२०१६ एशियानेट फिल्म पुरस्कार सर्वश्रेष्ठ सहायक अभिनेत्री के लिए फिल्म चार्ली के लिए\n",
            "===============================\n",
            "\t\t\t\t\t\n",
            " [list(['Kalpana', 'occupation', 'actor'])]\n",
            "\n",
            "\n",
            "*******************************************************************************\n",
            "२०१६ हेन्को फूल भारतीय फिल्म पुरस्कार सर्वश्रेष्ठ सहायक अभिनेत्री के लिए फिल्म चार्ली के लिए\n",
            "===============================\n",
            "\t\t\t\t\t\n",
            " [list(['Kalpana', 'occupation', 'actor'])\n",
            " list(['Kalpana', 'country of citizenship', 'India'])]\n",
            "\n",
            "\n",
            "*******************************************************************************\n",
            "२०१६ उत्तर अमेरिकी फिल्म पुरस्कार सर्वश्रेष्ठ सहायक अभिनेत्री फिल्म चार्ली के लिए\n",
            "===============================\n",
            "\t\t\t\t\t\n",
            " [list(['Kalpana', 'occupation', 'actor'])]\n",
            "\n",
            "\n",
            "*******************************************************************************\n",
            "कल्पना ने मलयालम टीवी चैनल पर कई धारावाहिक और साक्षात्कार की मेजबानी की है\n",
            "===============================\n",
            "\t\t\t\t\t\n",
            " [list(['Kalpana', 'languages spoken, written or signed', 'Malayalam'])]\n",
            "\n",
            "\n",
            "*******************************************************************************\n",
            "मलयाली दरबार (अमृता टीवी)\n",
            "===============================\n",
            "\t\t\t\t\t\n",
            " [list(['Kalpana', 'languages spoken, written or signed', 'Malayalam'])]\n",
            "\n",
            "\n",
            "*******************************************************************************\n",
            "हेयरमोक्स श्रीमती केरल (सूर्य टीवी)\n",
            "===============================\n",
            "\t\t\t\t\t\n",
            " [list(['Kalpana', 'place of birth', 'Kerala'])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_QqaFAR84Yy"
      },
      "source": [
        "### Conclusion :\r\n",
        "The result we get is fairly good. For a lot of sentences , we get triples that are relevant. Because we are using google translate to get english transliteration for the out of vocab hindi words, the result is even better. "
      ]
    }
  ]
}